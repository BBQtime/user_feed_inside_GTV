{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTV trail site split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inclusion criteria\n",
    "All head and neck cancer patients referred to primary curative or primary palliative radiation treatment with one of the following T-sites:\n",
    "- Oropharynx\n",
    "- Hypopharynx\n",
    "- Supraglottic larynx\n",
    "- Oral cavity\n",
    "\n",
    "#### Exclusion criteria\n",
    "All patients with cancer in the following sites are excluded.\n",
    "- Vocal cord\n",
    "- Sinonasal\n",
    "- Nasal cavity\n",
    "- Postoperative\n",
    "- Nasopharyngeal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import os\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./imagesTs/HNCDL_003.nii.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('dataset.json') as file:\n",
    "    task901_split = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n"
     ]
    }
   ],
   "source": [
    "def fetch_patient_id(data_list):\n",
    "    if data_list and isinstance(data_list[0], dict) and 'image' in data_list[0]:\n",
    "        # Handle training data (list of dictionaries)\n",
    "        return [os.path.basename(os.path.normpath(entry[\"image\"])).split(\".nii.gz\")[0] for entry in data_list]\n",
    "    else:\n",
    "        # Handle test data (list of strings)\n",
    "        return [os.path.basename(os.path.normpath(path)).split(\".nii.gz\")[0] for path in data_list]\n",
    "\n",
    "\n",
    "test_patients = fetch_patient_id(task901_split['test'])\n",
    "train_patients = fetch_patient_id(task901_split['training'])\n",
    "all_patients = train_patients + test_patients\n",
    "print(len(all_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>AARR</th>\n",
       "      <th>KOEN</th>\n",
       "      <th>ONSTYPE</th>\n",
       "      <th>PHARYNX</th>\n",
       "      <th>LARYNX</th>\n",
       "      <th>CAVORIS</th>\n",
       "      <th>SINONASA</th>\n",
       "      <th>SPYTKIR</th>\n",
       "      <th>T97</th>\n",
       "      <th>N97</th>\n",
       "      <th>M97</th>\n",
       "      <th>ST97</th>\n",
       "      <th>New_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HNCDL_001</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>HNCDL_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HNCDL_002</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>HNCDL_002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HNCDL_003</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>HNCDL_003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HNCDL_004</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>HNCDL_004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HNCDL_005</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>HNCDL_005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>HNCDL_894</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>HNCDL_894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>HNCDL_214</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>HNCDL_214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>HNCDL_058</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>HNCDL_058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>HNCDL_070</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>HNCDL_070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>HNCDL_363</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>HNCDL_363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PatientID  AARR  KOEN  ONSTYPE  PHARYNX  LARYNX  CAVORIS  SINONASA  \\\n",
       "0    HNCDL_001  2017     1        2        1       0        0         0   \n",
       "1    HNCDL_002  2017     1        3        0       0        8         0   \n",
       "2    HNCDL_003  2017     1        2        1       0        0         0   \n",
       "3    HNCDL_004  2015     1        2        1       0        0         0   \n",
       "4    HNCDL_005  2015     1        2        1       0        0         0   \n",
       "..         ...   ...   ...      ...      ...     ...      ...       ...   \n",
       "884  HNCDL_894  2014     1        2        1       0        0         0   \n",
       "886  HNCDL_214  2018     1        1        0       7        0         0   \n",
       "887  HNCDL_058  2016     1        3        0       0       11         0   \n",
       "888  HNCDL_070  2015     2        5        0       0        0         0   \n",
       "889  HNCDL_363  2017     1        5        0       0        0         0   \n",
       "\n",
       "     SPYTKIR  T97  N97  M97  ST97     New_ID  \n",
       "0          0    2    1    0     5  HNCDL_001  \n",
       "1          0    8    4    0     6  HNCDL_002  \n",
       "2          0    5    1    0     5  HNCDL_003  \n",
       "3          0    2    3    0     6  HNCDL_004  \n",
       "4          0    5    0    0     2  HNCDL_005  \n",
       "..       ...  ...  ...  ...   ...        ...  \n",
       "884        0    5    1    0     5  HNCDL_894  \n",
       "886        0    5    0    0     2  HNCDL_214  \n",
       "887        0   12    5    0     6  HNCDL_058  \n",
       "888        1    8    1    0     5  HNCDL_070  \n",
       "889        1   11    1    0     6  HNCDL_363  \n",
       "\n",
       "[567 rows x 14 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sites = pd.read_csv('sites_pre.csv')\n",
    "\n",
    "all_sites_patient_id = data_sites['PatientID']\n",
    "filtered_data = data_sites[data_sites['PatientID'].isin(all_patients)]\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 85\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_patients_for_experiment(data):\n",
    "    # Criteria for inclusion based on ONSTYPE, LARYNX, and PHARYNX\n",
    "    condition_onstype_1 = (data['ONSTYPE'] == 1) & (data['LARYNX'] < 7)\n",
    "    condition_onstype_2 = (data['ONSTYPE'] == 2) & ~((data['PHARYNX'] >= 10) & (data['PHARYNX'] <= 12))\n",
    "    condition_onstype_3 = (data['ONSTYPE'] == 3)\n",
    "    \n",
    "    # Combining conditions for inclusion\n",
    "    final_condition = condition_onstype_1 | condition_onstype_2 | condition_onstype_3\n",
    "    \n",
    "    # Filtering data based on the combined conditions for inclusion\n",
    "    included_data = data[final_condition]\n",
    "    \n",
    "    # Getting the excluded data\n",
    "    excluded_data = data[~final_condition]\n",
    "    \n",
    "    return included_data, excluded_data\n",
    "\n",
    "included_data, excluded_data = filter_patients_for_experiment(filtered_data)\n",
    "print(len(included_data), len(excluded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the included_data into training and testing sets (80% train, 20% test), stratifying on ONSTYPE\n",
    "train_data, test_data = train_test_split(included_data, test_size=0.2, stratify=included_data['ONSTYPE'], random_state=42)\n",
    "print(len(train_data), len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create a dictionary with PatientID lists for train_data, test_data and excluded_data\n",
    "data_dict = {\n",
    "    \"train\": train_data[\"PatientID\"].tolist(),\n",
    "    \"test\": test_data[\"PatientID\"].tolist(),\n",
    "    \"other_sites\": excluded_data[\"PatientID\"].tolist()\n",
    "}\n",
    "\n",
    "# Save the dictionary to a .json file with each PatientID on a new line\n",
    "with open(\"data_split_GTV_trail.json\", \"w\") as file:\n",
    "    json_data = json.dumps(data_dict, indent=4)\n",
    "    file.write(json_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
